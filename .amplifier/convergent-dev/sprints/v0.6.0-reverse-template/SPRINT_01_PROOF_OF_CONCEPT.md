# Sprint 1: End-to-End Proof of Concept

**Duration:** 2-3 days  
**Goal:** Working reverse template pipeline with naive source discovery  
**Value Delivered:** User can generate valid templates from existing docs TODAY

---

## ğŸ¯ Why This Sprint?

Sprint 1 proves the core concept works end-to-end. Even with naive source discovery (pattern matching only), users can:
- Generate valid templates from existing documentation
- See structure extraction in action
- Test on their own docs immediately
- Manually refine sources if needed

**This validates the approach and motivates the harder work in Sprint 2.**

We're building a vertical slice: parse â†’ discover â†’ assemble â†’ output. Each piece is simple, but together they deliver value.

---

## ğŸ“¦ Deliverables

### 1. Document Structure Parser
**Estimated Lines:** ~200 lines + 150 lines tests

**What it does:**
- Parses markdown files (README.md, CONTRIBUTING.md, etc.)
- Extracts heading hierarchy (H1, H2, H3)
- Identifies section boundaries and content blocks
- Captures structure for template mapping

**Why this sprint:**
Foundation for everything. Without structure extraction, we can't build templates.

**Implementation notes:**
- Use Python `mistune` or `markdown` library for parsing
- Build document tree representation (nested dict structure)
- Extract headings with level, text, and content
- Keep it simple - handle standard markdown only for now

**TDD approach:**
```python
# ğŸ”´ RED: Write test first
def test_parse_simple_readme():
    doc = "# Title\n\n## Section 1\n\nContent here\n\n## Section 2\n\nMore content"
    result = DocumentParser.parse(doc)
    assert result['sections'][0]['heading'] == 'Title'
    assert len(result['sections'][0]['subsections']) == 2
    # This will FAIL - parser doesn't exist yet

# ğŸŸ¢ GREEN: Write minimal code
class DocumentParser:
    @staticmethod
    def parse(markdown_text):
        # Minimal implementation to pass test
        # Use mistune to extract headings
        pass

# ğŸ”µ REFACTOR: Clean up, add features
# Extract into proper module structure
# Add better error handling
# Optimize heading extraction
```

---

### 2. Pattern-Based Source Discovery (Naive)
**Estimated Lines:** ~150 lines + 100 lines tests

**What it does:**
- Maintains mapping of section types â†’ typical source patterns
- Pattern matching for common section types
- Returns list of candidate source files per section

**Why this sprint:**
Proves source discovery works. Even simple pattern matching provides value (50-60% accuracy).

**Implementation notes:**
```python
SECTION_PATTERNS = {
    'installation': ['package.json', 'setup.py', 'pyproject.toml', 'requirements.txt'],
    'api reference': ['src/**/*.py', 'lib/**/*.js', 'api/**/*'],
    'configuration': ['config/**/*.yaml', '*.config.js', '.env.example'],
    'architecture': ['docs/architecture.md', 'src/core/**/*'],
    'contributing': ['CONTRIBUTING.md', '.github/**/*', 'docs/contributing.md'],
}

def discover_sources_naive(section_heading, section_content, project_root):
    """
    Match section heading against known patterns.
    Return list of files that match patterns.
    """
    # Normalize heading (lowercase, remove special chars)
    # Match against SECTION_PATTERNS
    # Use glob to find matching files in project_root
    # Return list of found files
    pass
```

**TDD approach:**
```python
# ğŸ”´ RED: Test first
def test_discover_installation_sources():
    sources = discover_sources_naive(
        section_heading="Installation",
        section_content="To install, run pip install...",
        project_root="/fake/project"
    )
    assert 'package.json' in sources or 'setup.py' in sources
    # FAILS - function doesn't exist

# ğŸŸ¢ GREEN: Implement
def discover_sources_naive(section_heading, section_content, project_root):
    # Simple pattern matching
    # Use glob to find files
    pass

# ğŸ”µ REFACTOR: Improve pattern matching
# Add more patterns
# Better file existence checking
# Handle project type detection
```

---

### 3. Template Assembly & Validation
**Estimated Lines:** ~150 lines + 100 lines tests

**What it does:**
- Assembles parsed structure + discovered sources into template.json
- Generates basic metadata (name, description, quadrant)
- Validates template structure
- Outputs valid template file

**Why this sprint:**
End-to-end delivery - produces usable template.json that works with existing `regen` command.

**Implementation notes:**
```python
def assemble_template(parsed_doc, source_mappings, output_path):
    """
    Build template.json from components.
    
    Template structure:
    {
        "name": "README-reversed",
        "description": "Auto-generated from existing README.md",
        "quadrant": "explanation",  # Default for now
        "sections": [
            {
                "heading": "Installation",
                "prompt": "Document installation instructions",  # Placeholder
                "sources": ["package.json", "setup.py"]
            }
        ]
    }
    """
    # Infer quadrant from section types (start with "explanation" default)
    # Map each section to template section
    # Generate placeholder prompts (Sprint 3 will improve these)
    # Validate against schema
    # Write to output_path
    pass
```

**TDD approach:**
```python
# ğŸ”´ RED: Test output structure
def test_assemble_valid_template():
    parsed_doc = {...}  # Mock parsed structure
    sources = {...}     # Mock source mappings
    
    template = assemble_template(parsed_doc, sources, "output.json")
    
    assert template['name'] == 'README-reversed'
    assert len(template['sections']) > 0
    assert template['sections'][0]['heading'] is not None
    # FAILS - function doesn't exist

# ğŸŸ¢ GREEN: Basic implementation
# ğŸ”µ REFACTOR: Validation, error handling
```

---

### 4. CLI Command Implementation (Basic)
**Estimated Lines:** ~100 lines + 50 lines tests

**What it does:**
- New command: `doc-evergreen template reverse <doc-path>`
- Orchestrates: parse â†’ discover â†’ assemble
- Basic progress output
- Saves template to `.doc-evergreen/templates/`

**Why this sprint:**
User-facing entry point. Makes everything usable.

**Implementation notes:**
```python
@click.command()
@click.argument('doc_path', type=click.Path(exists=True))
@click.option('--output', '-o', help='Output template path')
def reverse(doc_path, output):
    """Generate template from existing documentation."""
    
    print(f"ğŸ” Analyzing {doc_path}...")
    
    # Parse document
    with open(doc_path) as f:
        content = f.read()
    parsed_doc = DocumentParser.parse(content)
    print(f"ğŸ“ Found {len(parsed_doc['sections'])} sections")
    
    # Discover sources (naive)
    project_root = Path(doc_path).parent
    source_mappings = {}
    for section in parsed_doc['sections']:
        sources = discover_sources_naive(
            section['heading'], 
            section['content'],
            project_root
        )
        source_mappings[section['id']] = sources
    print(f"âœ… Found {len(source_mappings)} source mappings")
    
    # Assemble template
    template_name = Path(doc_path).stem + '-reversed'
    output_path = output or f".doc-evergreen/templates/{template_name}.json"
    assemble_template(parsed_doc, source_mappings, output_path)
    
    print(f"âœ… Template generated: {output_path}")
    print("\nNext steps:")
    print(f"1. Review: cat {output_path}")
    print(f"2. Test: doc-evergreen regen --template {output_path}")
```

**TDD approach:**
```python
# ğŸ”´ RED: Integration test
def test_reverse_command_end_to_end(tmp_path):
    # Create test README
    readme = tmp_path / "README.md"
    readme.write_text("# Test\n\n## Installation\n\nRun pip install")
    
    # Run command
    runner = CliRunner()
    result = runner.invoke(reverse, [str(readme)])
    
    # Assert template created
    assert result.exit_code == 0
    assert "Template generated" in result.output
    template_path = tmp_path / ".doc-evergreen/templates/README-reversed.json"
    assert template_path.exists()
    # FAILS - command doesn't exist

# ğŸŸ¢ GREEN: Implement basic command
# ğŸ”µ REFACTOR: Error handling, better output
```

---

## ğŸš« What Gets Punted (Deliberately Excluded)

### âŒ LLM Content Analysis
- **Why**: Don't need to understand section intent yet
- **Reconsider**: Sprint 3 (after source discovery works)
- Pattern matching is sufficient for Sprint 1

### âŒ Semantic Search for Sources
- **Why**: Pattern matching proves the concept
- **Reconsider**: Sprint 2 (the main event)
- Naive discovery is 50-60% accurate, good enough for validation

### âŒ Intelligent Prompt Generation
- **Why**: Placeholder prompts work for testing
- **Reconsider**: Sprint 3
- Users can manually refine prompts after generation

### âŒ CLI Options (--dry-run, --verbose)
- **Why**: Basic command proves usability
- **Reconsider**: Sprint 4 (polish)
- Simple happy path is sufficient

### âŒ Advanced Error Handling
- **Why**: Basic validation is enough
- **Reconsider**: Sprint 4
- Focus on working pipeline first

---

## ğŸ§ª Testing Requirements

### TDD Approach (Red-Green-Refactor)

**Day 1:**
- ğŸ”´ Write failing tests for DocumentParser
- ğŸŸ¢ Implement DocumentParser (minimal)
- ğŸ”µ Refactor DocumentParser
- âœ… Commit (tests green)

**Day 2:**
- ğŸ”´ Write failing tests for source discovery
- ğŸŸ¢ Implement pattern matching
- ğŸ”µ Refactor pattern logic
- âœ… Commit (tests green)

**Day 3:**
- ğŸ”´ Write failing tests for template assembly
- ğŸŸ¢ Implement assembly logic
- ğŸ”µ Refactor validation
- ğŸ”´ Write end-to-end CLI test
- ğŸŸ¢ Wire everything together
- âœ… Final commit & sprint review

### Unit Tests (Write First)
- **DocumentParser**:
  - Parse simple markdown (H1, H2)
  - Handle nested sections (H1 â†’ H2 â†’ H3)
  - Extract section content correctly
  - Handle edge cases (empty sections, no headings)

- **Pattern-based discovery**:
  - Match "Installation" â†’ package files
  - Match "API Reference" â†’ code files
  - Match "Contributing" â†’ CONTRIBUTING.md
  - Handle no matches (return empty list)
  - Handle multiple matches (return all)

- **Template assembly**:
  - Generate valid JSON structure
  - Include all sections from parsed doc
  - Map sources to sections
  - Generate placeholder prompts
  - Validate against schema

### Integration Tests (After Unit Tests Pass)
- **End-to-end workflow**:
  - Parse doc-evergreen README
  - Discover sources for each section
  - Generate valid template
  - Template can be used with `regen` command

### Manual Testing (After Automated Tests Pass)
- [ ] Run on doc-evergreen's README
- [ ] Inspect generated template structure
- [ ] Verify sources are reasonable (50-60% accuracy expected)
- [ ] Test template with `regen` command
- [ ] Compare regenerated output to original

**Test Coverage Target:** >80% for new code

---

## ğŸ“Š What You Learn

After Sprint 1, you'll discover:

1. **Structure extraction feasibility**
   - Can we reliably parse markdown structure?
   - What edge cases exist in real docs?
   - Does heading hierarchy map well to templates?

2. **Pattern matching accuracy**
   - How often do patterns find correct sources?
   - What patterns are most reliable?
   - Where does naive discovery fail?
   â†’ **This motivates Sprint 2's intelligent discovery**

3. **Template generation viability**
   - Does auto-generated template structure make sense?
   - Can users actually use the generated templates?
   - What's missing for production use?
   â†’ **This validates the v0.6.0 approach**

4. **User workflow validation**
   - Is the `reverse â†’ regen` workflow intuitive?
   - What friction points exist?
   - What features are most needed?

---

## âœ… Success Criteria

### Must Have
- âœ… CLI command `doc-evergreen template reverse README.md` works
- âœ… Generates valid template.json with structure matching input doc
- âœ… Pattern-based source discovery finds sources for common sections (50-60% accuracy)
- âœ… Template can be used immediately with `regen` command
- âœ… All tests pass with >80% coverage

### Nice to Have (Defer if Time Constrained)
- âŒ Support for non-markdown formats (RST, etc.) â†’ Sprint 4
- âŒ Advanced pattern matching â†’ Sprint 2
- âŒ Detailed progress output â†’ Sprint 4

---

## ğŸ› ï¸ Technical Approach

### Architecture
```
CLI Command (template reverse)
  â†“
ReverseTemplateOrchestrator
  â”œâ”€â†’ DocumentParser
  â”‚     Input: markdown text
  â”‚     Output: {title, sections: [{heading, level, content}]}
  â”‚
  â”œâ”€â†’ NaiveSourceDiscoverer
  â”‚     Input: section heading + content
  â”‚     Output: [list of source file paths]
  â”‚
  â””â”€â†’ TemplateAssembler
        Input: parsed doc + source mappings
        Output: template.json
```

### Key Decisions

**1. Use mistune for markdown parsing**
- Well-tested library
- Handles edge cases
- Good performance
- Alternative: markdown-it-py

**2. Start with pattern dictionary**
- Simple to implement
- Easy to test
- Sufficient for proof of concept
- Foundation for Sprint 2 improvements

**3. Placeholder prompts**
- "Document the {section_heading} for this project"
- Good enough for Sprint 1
- Sprint 3 will generate intelligent prompts

**4. Default to "explanation" quadrant**
- Most READMEs are explanatory
- Can be manually refined
- Sprint 3 will infer quadrant properly

---

## ğŸ“… Implementation Order

### Day 1: Document Parser
- ğŸ”´ Write DocumentParser tests
- ğŸŸ¢ Implement basic parsing with mistune
- ğŸ”µ Refactor into clean module
- Test on doc-evergreen README
- âœ… Commit

### Day 2: Source Discovery + Assembly
- ğŸ”´ Write source discovery tests
- ğŸŸ¢ Implement pattern matching
- ğŸ”µ Refactor pattern logic
- ğŸ”´ Write assembly tests
- ğŸŸ¢ Implement template builder
- ğŸ”µ Refactor validation
- âœ… Commit

### Day 3: CLI + Integration
- ğŸ”´ Write CLI integration test
- ğŸŸ¢ Wire components together
- ğŸ”µ Refactor error handling
- Manual testing on real docs
- Documentation update
- âœ… Final commit & sprint review

---

## ğŸ¯ Known Limitations (By Design)

1. **Pattern matching is naive (50-60% accuracy)**
   - Acceptable: Proves concept, Sprint 2 will improve
   - Users can manually refine sources

2. **Placeholder prompts aren't intelligent**
   - Acceptable: Sprint 3 will generate proper prompts
   - Basic prompts work for testing reverse â†’ regen workflow

3. **No quadrant inference**
   - Acceptable: Defaults to "explanation"
   - Sprint 3 will analyze content to infer quadrant

4. **Limited error handling**
   - Acceptable: Happy path testing only
   - Sprint 4 will add robust error handling

5. **No CLI options (--dry-run, --verbose, etc.)**
   - Acceptable: Basic command proves usability
   - Sprint 4 will add polish

---

## ğŸ”„ Next Sprint Preview

After Sprint 1 ships, the **most pressing need** will be:

**Better source discovery** - Pattern matching finds sources 50-60% of the time, but we need 70-80% accuracy for the feature to be truly useful. Sprint 2 will add:
- Semantic search (grep for keywords from section content)
- LLM relevance scoring (rate sources 0-10 for each section)
- Smart ranking and filtering (top 3-5 sources per section)

Sprint 1 proves the pipeline works. Sprint 2 makes it accurate enough to ship.

---

**Ready to start building?** ğŸš€ Follow the TDD approach and commit frequently!
